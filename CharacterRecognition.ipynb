{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c62fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "import MathNet as mnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3631a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models\\mathnet\\mathnet22.ml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434ef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e90c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, W) = (400, 400)\n",
    "class SlidingWindowObjectDetection():\n",
    "    def __init__(self, pretrained_classifier_path, kwargs):\n",
    "        self.model = mnt.MathNet()\n",
    "        self.model.load_state_dict(torch.load(pretrained_classifier_path))\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(device)\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def test(self, image, step, ws):\n",
    "        potential = []\n",
    "        for y in range(0, image.shape[0] - ws[1], step):\n",
    "            for x in range(0, image.shape[1] - ws[0], step):\n",
    "                crop_img = image[y:y+28, x:x+28]\n",
    "                #print(type(image), type(crop_img))\n",
    "                crop_tensor = transforms.ToTensor()\n",
    "                \n",
    "               \n",
    "                \n",
    "                thresh = 120\n",
    "                ret,thresh_img = cv2.threshold(crop_img, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                #find contours\n",
    "                contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                img_contours = np.uint8(np.zeros((crop_img.shape[0],crop_img.shape[1])))\n",
    "                cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "                \n",
    "                if (len(contours) > 1):\n",
    "                    #print(x,y, len(contours))\n",
    "                    #img = Image.fromarray(crop_img.astype('uint8'))\n",
    "                    #img = Image.fromarray(img_contours.astype('uint8'))\n",
    "                    #display(img)\n",
    "                    potential.append(crop_img)\n",
    "        return potential\n",
    "    \n",
    "    def predict(self, lst):\n",
    "        res = []\n",
    "        for image in lst:\n",
    "            img = Image.fromarray(image.astype('uint8'))\n",
    "            convert_tensor = transforms.Compose([\n",
    "                transforms.Resize((28,28)),\n",
    "                transforms.Grayscale(1),\n",
    "                transforms.ToTensor()\n",
    "\n",
    "            ])\n",
    "\n",
    "            \n",
    "            x_image = convert_tensor(img)\n",
    "            x_image = x_image.unsqueeze(0).float()\n",
    "            x_image = x_image.to(device)\n",
    "\n",
    "            preds = self.model(x_image) \n",
    "            prob = preds.max()\n",
    "            if prob >= self.kwargs['MIN_CONF']:\n",
    "                print(prob.item(), (map_pred(preds.argmax()), preds))\n",
    "                img = Image.fromarray(image.astype('uint8'))\n",
    "                display(img)\n",
    "            \n",
    "                res.append((map_pred(preds.argmax()), preds))\n",
    "\n",
    "        \n",
    "    def visualize_rois(self, rois):\n",
    "        fig, axes = plt.subplots(1, len(rois), figsize=(20, 6))\n",
    "        for ax, roi in zip(axes, rois):\n",
    "            ax.imshow(roi, cmap='gray')\n",
    "\n",
    "    \n",
    "    def get_preds(self, rois, locs):\n",
    "        rois = np.array(rois, dtype=\"float32\")\n",
    "        preds = self.predict(rois)\n",
    "        #preds = list(zip(preds.argmax(axis=1).tolist(), preds.max(axis=1).tolist()))\n",
    "        res = []\n",
    "        for i in range(0, len(preds)):\n",
    "            res.append((map_pred(preds[i].argmax()), preds[i].max()))\n",
    "        #print(res)\n",
    "        labels = {}\n",
    "\n",
    "        for (i, p) in enumerate(res):\n",
    "            (label, prob) = p\n",
    "            if prob >= self.kwargs['MIN_CONF']:\n",
    "                box = locs[i]\n",
    "                L = labels.get(label, [])\n",
    "                L.append((box, prob))\n",
    "                labels[label] = L\n",
    "        return preds, labels\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        potential = self.test(img, self.kwargs['WIN_STEP'], self.kwargs['ROI_SIZE'])\n",
    "        self.predict(potential)\n",
    "        \n",
    "        rois, locs = self.get_rois_and_locs()\n",
    "        \n",
    "        preds, labels = self.get_preds(rois, locs)\n",
    "        nms_labels = self.apply_nms(labels)\n",
    "        if self.kwargs['VISUALIZE']:\n",
    "            self.visualize_preds(img, nms_labels)\n",
    "        return nms_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c2aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    PYR_SCALE=1.25,\n",
    "    WIN_STEP=3,\n",
    "    ROI_SIZE=(21, 21),\n",
    "    INPUT_SIZE=(28, 28),\n",
    "    VISUALIZE=True,\n",
    "    MIN_CONF=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'TEST/5.jpg'\n",
    "image = cv2.imread(IMAGE_NAME)\n",
    "\n",
    "img_grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#set a thresh\n",
    "thresh = 120\n",
    "\n",
    "#get threshold image\n",
    "ret,thresh_img = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#find contours\n",
    "contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img_contours = np.uint8(np.zeros((image.shape[0],image.shape[1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133f6a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74f8d7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n"
     ]
    }
   ],
   "source": [
    "sw = SlidingWindowObjectDetection(MODEL_PATH, kwargs)\n",
    "IMAGE_NAME = 'TEST/5.jpg'\n",
    "image = cv2.imread(IMAGE_NAME)\n",
    "img_grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print('END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ea2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f789fdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af995677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_letter(image, dst):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b3e62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Letter:\n",
    "    def __init__(self, x, y, w, h, img):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "        self.image = img\n",
    "        \n",
    "        self.line = 0\n",
    "        \n",
    "        self.bottom = self.y + self.height\n",
    "        self.top = self.y\n",
    "        self.left = self.x\n",
    "        self.right = self.x + self.width\n",
    "        \n",
    "    def resize():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e0d158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_extract(image_file):\n",
    "    img = cv2.imread(image_file)\n",
    "    output = img.copy()\n",
    "    cv2.imshow('MyPhoto', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    thresh = 100\n",
    "    thresh_img = cv2.adaptiveThreshold(gray, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,5,8)\n",
    "    cv2.imshow('thresh_img', thresh_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img_erode = thresh_img#cv2.erode(thresh_img, np.ones((3, 3), np.uint8), iterations=3)\n",
    "#     cv2.imshow('MyPhoto', img_erode)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "    cv2.imshow('img_contours', img_contours )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "       \n",
    "    # Filter contours\n",
    "    mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 10 and cv2.contourArea(contour) < 100:\n",
    "            cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "        else:\n",
    "            pass\n",
    "#             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "#             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "#             print(w*h, cv2.contourArea(contour))\n",
    "#             cv2.imshow(str(idx), dummy )\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "            \n",
    "#     # apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img,img, mask= mask)   \n",
    "    cv2.imshow('result', result )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "    cv2.imshow('Contours', img_contours )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    letters = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        if hierarchy[0][idx][3] != -1:\n",
    "            continue\n",
    "#         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "#         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "#         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "#         cv2.imshow('MyPhoto', mask_contour)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "#         ii = cv2.imread('mask.png')\n",
    "#         cv2.imshow('MyPhoto', ii )\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        crop_img = img_erode[y:y+h, x:x+w]\n",
    "        #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "        size_max = max(w, h)\n",
    "        letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "        if w > h:\n",
    "            y_pos = size_max//2 - h//2\n",
    "            letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "        elif w < h:\n",
    "            x_pos = size_max//2 - w//2\n",
    "            letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "        else:\n",
    "            letter_square = crop_img\n",
    "        \n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "        inverted = cv2.bitwise_not(letter_square)\n",
    "        \n",
    "        letter = Letter(x,y,w,h,letter_square)\n",
    "        letters.append(letter)\n",
    "\n",
    "    letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "    aaa = Image.fromarray(output.astype('uint8'))\n",
    "    display(aaa)\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc547e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d2025e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_size(lst):\n",
    "    if len(lst) <= 0:\n",
    "        return (0, 0)\n",
    "    avg_w = 0\n",
    "    avg_h = 0\n",
    "    for letter in lst:\n",
    "        avg_w += letter.width\n",
    "        avg_h += letter.height\n",
    "    avg_w /= len(lst)\n",
    "    avg_h /= len(lst)\n",
    "    \n",
    "    return (avg_w, avg_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf06bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_str(model, image_file, tp=1):\n",
    "    letters = letters_extract(image_file)   \n",
    "    \n",
    "    print('SHAPE: ', np.array(letters,dtype=object).shape)\n",
    "    s_out = \"\"\n",
    "    if len(letters) == 0:\n",
    "        return \"Found nothing\"\n",
    "    (avg_w, avg_h) = average_size(letters)\n",
    "    print((avg_w, avg_h))\n",
    "    \n",
    "    # True sorting by Y axis\n",
    "    line = 0\n",
    "    for i in range (1, len(letters)):\n",
    "        if letters[i].top > letters[i-1].bottom:\n",
    "            line += 1\n",
    "        letters[i].line = line\n",
    "    letters.sort(key=lambda ll: (ll.line, ll.x), reverse=False)  \n",
    "    \n",
    "    prev_loc = (letters[0].x, letters[0].y)\n",
    "    prev_size = (letters[0].width, letters[0].height)\n",
    "    prev_line = letters[0].line\n",
    "    #for i in range(1):\n",
    "    for i in range(len(letters)):\n",
    "        img = Image.fromarray(letters[i].image.astype('uint8'))\n",
    "        convert_tensor = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.ToTensor()\n",
    "\n",
    "        ])        \n",
    "        x_image = convert_tensor(img)\n",
    "        aaa = transforms.ToPILImage()\n",
    "        display(aaa(x_image))\n",
    "        x_image = x_image.unsqueeze(0).float()\n",
    "        x_image = x_image.to(device)\n",
    "        pred = model(x_image) \n",
    "        am = mnt.map_pred(pred.argmax().item())\n",
    "        #print(letters[i].image.shape, map_pred(pred.argmax().item()), am)\n",
    "        #dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
    "        #print(am)\n",
    "        x = letters[i].x\n",
    "        y = letters[i].y\n",
    "        size = (letters[i].width, letters[i].height)\n",
    "        if (letters[i].line >  prev_line):\n",
    "            s_out += \"\\n\"\n",
    "            prev_line = letters[i].line\n",
    "        prev_loc, prev_size = (x,y), size\n",
    "        s_out += am + ' '\n",
    "        print(letters[i].image.shape, map_pred(pred.argmax().item()), am)\n",
    "        \n",
    "    return s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38953a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION\n"
     ]
    }
   ],
   "source": [
    "model = mnt.MathNet()\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print('EVALUATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bf68e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=468x370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE:  (13,)\n",
      "(13.0, 13.615384615384615)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'map_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mimg_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEST/5.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESULT:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "Cell \u001b[1;32mIn[28], line 37\u001b[0m, in \u001b[0;36mimg_to_str\u001b[1;34m(model, image_file, tp)\u001b[0m\n\u001b[0;32m     35\u001b[0m x_image \u001b[38;5;241m=\u001b[39m x_image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x_image) \n\u001b[1;32m---> 37\u001b[0m am \u001b[38;5;241m=\u001b[39m \u001b[43mmap_pred\u001b[49m(pred\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#print(letters[i].image.shape, map_pred(pred.argmax().item()), am)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(am)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m letters[i]\u001b[38;5;241m.\u001b[39mx\n",
      "\u001b[1;31mNameError\u001b[0m: name 'map_pred' is not defined"
     ]
    }
   ],
   "source": [
    "s = img_to_str(model, 'TEST/5.jpg', 1)\n",
    "print('RESULT:')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('TEST/h.jpg')\n",
    "edges = cv2.Canny(img,25,255,L2gradient=False)\n",
    "cv2.imshow('Start image', img)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.show()\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cc3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a8dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread('TEST/real4.jpg')\n",
    "output = img.copy()\n",
    "cv2.imshow('MyPhoto', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.blur(gray, (3, 3))\n",
    "cv2.imshow('blurred', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#set a thresh\n",
    "thresh = 110\n",
    "ret, thresh_img = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# cv2.imshow('thresh_img', thresh_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "thresh_img = cv2.adaptiveThreshold(blurred, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,5,8)\n",
    "cv2.imshow('thresh_img', thresh_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#thresh_img = cv2.bitwise_not(thresh_img)\n",
    "\n",
    "# opening = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# closed = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8))\n",
    "# cv2.imshow('closed', closed)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "img_erode = cv2.erode(thresh_img, np.ones((3, 3), np.uint8), iterations=1)\n",
    "#img_erode = cv2.dilate(img_erode, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "cv2.imshow('img_erode', img_erode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Get contours\n",
    "contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "cv2.imshow('MyPhoto', img_contours )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Filter contours\n",
    "mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "for idx, contour in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    if cv2.contourArea(contour) > 10 and cv2.contourArea(contour) < 10000:\n",
    "        cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "    else:\n",
    "        pass\n",
    "#             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "#             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "#             print(w*h, cv2.contourArea(contour))\n",
    "#             cv2.imshow(str(idx), dummy )\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "\n",
    "#     # apply the mask to the original image\n",
    "result = cv2.bitwise_and(img,img, mask=mask)   \n",
    "cv2.imshow('result', mask )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "cv2.imshow('img_contours', img_contours )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "letters = []\n",
    "for idx, contour in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "    if hierarchy[0][idx][3] != -1:\n",
    "        continue\n",
    "#         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "#         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "#         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "#         cv2.imshow('MyPhoto', mask_contour)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "#         ii = cv2.imread('mask.png')\n",
    "#         cv2.imshow('MyPhoto', ii )\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    crop_img = img_erode[y:y+h, x:x+w]\n",
    "    #crop_img = cv2.bitwise_not(crop_img)\n",
    "    #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "    size_max = max(w, h)\n",
    "    letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "    if w > h:\n",
    "        y_pos = size_max//2 - h//2\n",
    "        letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "    elif w < h:\n",
    "        x_pos = size_max//2 - w//2\n",
    "        letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "    else:\n",
    "        letter_square = crop_img\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "    inverted = cv2.bitwise_not(letter_square)\n",
    "    \n",
    "    aaa = transforms.ToPILImage()\n",
    "    display(aaa(letter_square))\n",
    "    \n",
    "    letter = Letter(x,y,w,h,letter_square)\n",
    "    letters.append(letter)\n",
    "\n",
    "letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "aaa = Image.fromarray(output.astype('uint8'))\n",
    "display(aaa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb448a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4c1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e0425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af59fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a15b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28961b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contours\n",
    "    contours, hierarchy = cv2.findContours(sobel2, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "    cv2.imshow('MyPhoto', img_contours )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Filter contours\n",
    "    mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 100 and cv2.contourArea(contour) < 10000:\n",
    "            cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "        else:\n",
    "            pass\n",
    "    #             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    #             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "    #             print(w*h, cv2.contourArea(contour))\n",
    "    #             cv2.imshow(str(idx), dummy )\n",
    "    #             cv2.waitKey(0)\n",
    "    #             cv2.destroyAllWindows()\n",
    "\n",
    "    #     # apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img,img, mask=mask)   \n",
    "#     cv2.imshow('result', mask )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "#     cv2.imshow('img_contours', img_contours )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        if hierarchy[0][idx][3] != -1:\n",
    "            continue\n",
    "    #         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "    #         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "    #         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "    #         cv2.imshow('MyPhoto', mask_contour)\n",
    "    #         cv2.waitKey(0)\n",
    "    #         cv2.destroyAllWindows()\n",
    "\n",
    "    #         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "    #         ii = cv2.imread('mask.png')\n",
    "    #         cv2.imshow('MyPhoto', ii )\n",
    "    #         cv2.waitKey(0)\n",
    "    #         cv2.destroyAllWindows()\n",
    "        crop_img = gray[y:y+h, x:x+w]\n",
    "        #crop_img = cv2.bitwise_not(crop_img)\n",
    "        #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "        size_max = max(w, h)\n",
    "        letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "        if w > h:\n",
    "            y_pos = size_max//2 - h//2\n",
    "            letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "        elif w < h:\n",
    "            x_pos = size_max//2 - w//2\n",
    "            letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "        else:\n",
    "            letter_square = crop_img\n",
    "\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "        inverted = cv2.bitwise_not(letter_square)\n",
    "\n",
    "        #aaa = transforms.ToPILImage()\n",
    "        #display(aaa(letter_square))\n",
    "\n",
    "        letter = Letter(x,y,w,h,letter_square)\n",
    "        letters.append(letter)\n",
    "\n",
    "    letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "    aaa = Image.fromarray(output.astype('uint8'))\n",
    "    display(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603e35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
