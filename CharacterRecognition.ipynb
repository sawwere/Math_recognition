{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c62fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3631a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes = ['(', ')', ',', '-', \n",
    "#                    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "#                    'A', '[', 'α', 'and', 'β', '∃', 'F', '∀', \n",
    "#                    'γ', 'λ', 'μ', 'ω', 'or', 'φ', '→', \n",
    "#                    'σ', 'sqrt', 'θ', 'v', 'x', 'y', 'z']\n",
    "\n",
    "classes = ['(', ')', '+', ',', '-', \n",
    "                     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                     'A', 'F','α','and','β', 'delta', '∃', '∀',\n",
    "                     'γ', 'λ', 'μ', 'not','ω','or','φ','pi','psi','→',\n",
    "                     'σ','tau','θ','v','x', 'y', 'z']\n",
    "\n",
    "NUM_CLASSES = len(classes)\n",
    "\n",
    "\n",
    "def map_pred(ind):\n",
    "    if ind < NUM_CLASSES:\n",
    "        return classes[ind]\n",
    "    return 'ERROR MAPPIMG'\n",
    "\n",
    "MODEL_PATH = 'models/mathnet/mathnet39.ml'\n",
    "NUM_CLASSES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f64ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidiumBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_percentage, is_reducer=True):\n",
    "        super(ResidiumBlock, self).__init__()\n",
    "        self.dropout_percentage = dropout_percentage\n",
    "        self.is_reducer = is_reducer\n",
    "        if self.is_reducer:\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                                         kernel_size=3, padding=1, stride=2)\n",
    "        else:\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                                         kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, \n",
    "                                     kernel_size=3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.act1  = torch.nn.ReLU()\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, \n",
    "                                     kernel_size=3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, \n",
    "                                     kernel_size=3, padding=1)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.act2  = torch.nn.ReLU()\n",
    "        #self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_percentage)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if not self.is_reducer:\n",
    "            x += identity\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        identity = x\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x += identity\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03687eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathNet(torch.nn.Module):\n",
    "    def __init__(self, out_size=NUM_CLASSES):\n",
    "        super(MathNet, self).__init__()\n",
    "        self.dropout_percentage = 0.25\n",
    "        \n",
    "        # 224x224x1 -> 112x112x64\n",
    "        self.conv1 =  nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.block1 = ResidiumBlock(64, 64, self.dropout_percentage, False)\n",
    "        self.block2 = ResidiumBlock(64, 128, self.dropout_percentage)\n",
    "        self.block3 = ResidiumBlock(128, 256, self.dropout_percentage)\n",
    "        self.block4 = ResidiumBlock(256, 512, self.dropout_percentage)\n",
    "\n",
    "        self.pool3 = torch.nn.AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
    "        self.dropout3 = nn.Dropout(p=self.dropout_percentage)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(512, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc1(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8af6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434ef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e90c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, W) = (400, 400)\n",
    "class SlidingWindowObjectDetection():\n",
    "    def __init__(self, pretrained_classifier_path, kwargs):\n",
    "        self.model = MathNet()\n",
    "        self.model.load_state_dict(torch.load(pretrained_classifier_path))\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(device)\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def test(self, image, step, ws):\n",
    "        potential = []\n",
    "        for y in range(0, image.shape[0] - ws[1], step):\n",
    "            for x in range(0, image.shape[1] - ws[0], step):\n",
    "                crop_img = image[y:y+28, x:x+28]\n",
    "                #print(type(image), type(crop_img))\n",
    "                crop_tensor = transforms.ToTensor()\n",
    "                \n",
    "               \n",
    "                \n",
    "                thresh = 120\n",
    "                ret,thresh_img = cv2.threshold(crop_img, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                #find contours\n",
    "                contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                img_contours = np.uint8(np.zeros((crop_img.shape[0],crop_img.shape[1])))\n",
    "                cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "                \n",
    "                if (len(contours) > 1):\n",
    "                    #print(x,y, len(contours))\n",
    "                    #img = Image.fromarray(crop_img.astype('uint8'))\n",
    "                    #img = Image.fromarray(img_contours.astype('uint8'))\n",
    "                    #display(img)\n",
    "                    potential.append(crop_img)\n",
    "        return potential\n",
    "    \n",
    "    def predict(self, lst):\n",
    "        res = []\n",
    "        for image in lst:\n",
    "            img = Image.fromarray(image.astype('uint8'))\n",
    "            convert_tensor = transforms.Compose([\n",
    "                transforms.Resize((28,28)),\n",
    "                transforms.Grayscale(1),\n",
    "                transforms.ToTensor()\n",
    "\n",
    "            ])\n",
    "\n",
    "            \n",
    "            x_image = convert_tensor(img)\n",
    "            x_image = x_image.unsqueeze(0).float()\n",
    "            x_image = x_image.to(device)\n",
    "\n",
    "            preds = self.model(x_image) \n",
    "            prob = preds.max()\n",
    "            if prob >= self.kwargs['MIN_CONF']:\n",
    "                print(prob.item(), (map_pred(preds.argmax()), preds))\n",
    "                img = Image.fromarray(image.astype('uint8'))\n",
    "                display(img)\n",
    "            \n",
    "                res.append((map_pred(preds.argmax()), preds))\n",
    "\n",
    "        \n",
    "    def visualize_rois(self, rois):\n",
    "        fig, axes = plt.subplots(1, len(rois), figsize=(20, 6))\n",
    "        for ax, roi in zip(axes, rois):\n",
    "            ax.imshow(roi, cmap='gray')\n",
    "\n",
    "    \n",
    "    def get_preds(self, rois, locs):\n",
    "        rois = np.array(rois, dtype=\"float32\")\n",
    "        preds = self.predict(rois)\n",
    "        #preds = list(zip(preds.argmax(axis=1).tolist(), preds.max(axis=1).tolist()))\n",
    "        res = []\n",
    "        for i in range(0, len(preds)):\n",
    "            res.append((map_pred(preds[i].argmax()), preds[i].max()))\n",
    "        #print(res)\n",
    "        labels = {}\n",
    "\n",
    "        for (i, p) in enumerate(res):\n",
    "            (label, prob) = p\n",
    "            if prob >= self.kwargs['MIN_CONF']:\n",
    "                box = locs[i]\n",
    "                L = labels.get(label, [])\n",
    "                L.append((box, prob))\n",
    "                labels[label] = L\n",
    "        return preds, labels\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        potential = self.test(img, self.kwargs['WIN_STEP'], self.kwargs['ROI_SIZE'])\n",
    "        self.predict(potential)\n",
    "        \n",
    "        rois, locs = self.get_rois_and_locs()\n",
    "        \n",
    "        preds, labels = self.get_preds(rois, locs)\n",
    "        nms_labels = self.apply_nms(labels)\n",
    "        if self.kwargs['VISUALIZE']:\n",
    "            self.visualize_preds(img, nms_labels)\n",
    "        return nms_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c2aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    PYR_SCALE=1.25,\n",
    "    WIN_STEP=3,\n",
    "    ROI_SIZE=(21, 21),\n",
    "    INPUT_SIZE=(28, 28),\n",
    "    VISUALIZE=True,\n",
    "    MIN_CONF=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = '5.jpg'\n",
    "image = cv2.imread(IMAGE_NAME)\n",
    "\n",
    "img_grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#set a thresh\n",
    "thresh = 120\n",
    "\n",
    "#get threshold image\n",
    "ret,thresh_img = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#find contours\n",
    "contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img_contours = np.uint8(np.zeros((image.shape[0],image.shape[1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133f6a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f8d7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/mathnet/mathnet39.ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sw \u001b[38;5;241m=\u001b[39m \u001b[43mSlidingWindowObjectDetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m IMAGE_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(IMAGE_NAME)\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mSlidingWindowObjectDetection.__init__\u001b[1;34m(self, pretrained_classifier_path, kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pretrained_classifier_path, kwargs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m MathNet()\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_classifier_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mF:\\Programs\\Anaconda3\\envs\\My_PyTorch\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mF:\\Programs\\Anaconda3\\envs\\My_PyTorch\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mF:\\Programs\\Anaconda3\\envs\\My_PyTorch\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/mathnet/mathnet39.ml'"
     ]
    }
   ],
   "source": [
    "sw = SlidingWindowObjectDetection(MODEL_PATH, kwargs)\n",
    "IMAGE_NAME = '5.jpg'\n",
    "image = cv2.imread(IMAGE_NAME)\n",
    "img_grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print('END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ea2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, dst):\n",
    "    x = float(dst) / image.shape[1]\n",
    "    y = float(dst) / image.shape[0]\n",
    "    return cv2.resize(image, (0,0), fx=x,fy=y, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af995677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_letter(image, dst):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Letter:\n",
    "    def __init__(self, x, y, w, h, img):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "        self.image = img\n",
    "        \n",
    "        self.line = 0\n",
    "        \n",
    "        self.bottom = self.y + self.height\n",
    "        self.top = self.y\n",
    "        self.left = self.x\n",
    "        self.right = self.x + self.width\n",
    "        \n",
    "    def resize():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_extract(image_file):\n",
    "    img = cv2.imread(image_file)\n",
    "    output = img.copy()\n",
    "    cv2.imshow('MyPhoto', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #set a thresh\n",
    "    thresh = 100\n",
    "    ret, thresh_img = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('MyPhoto', thresh_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img_erode = cv2.erode(thresh_img, np.ones((3, 3), np.uint8), iterations=3)\n",
    "#     cv2.imshow('MyPhoto', img_erode)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "#     cv2.imshow('MyPhoto', img_contours )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "       \n",
    "    # Filter contours\n",
    "    mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 100 and cv2.contourArea(contour) < 10000:\n",
    "            cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "        else:\n",
    "            pass\n",
    "#             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "#             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "#             print(w*h, cv2.contourArea(contour))\n",
    "#             cv2.imshow(str(idx), dummy )\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "            \n",
    "#     # apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img,img, mask= mask)   \n",
    "#     cv2.imshow('result', result )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "#     cv2.imshow('MyPhoto', img_contours )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "    letters = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        if hierarchy[0][idx][3] != -1:\n",
    "            continue\n",
    "#         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "#         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "#         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "#         cv2.imshow('MyPhoto', mask_contour)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "#         ii = cv2.imread('mask.png')\n",
    "#         cv2.imshow('MyPhoto', ii )\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        crop_img = img_erode[y:y+h, x:x+w]\n",
    "        #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "        size_max = max(w, h)\n",
    "        letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "        if w > h:\n",
    "            y_pos = size_max//2 - h//2\n",
    "            letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "        elif w < h:\n",
    "            x_pos = size_max//2 - w//2\n",
    "            letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "        else:\n",
    "            letter_square = crop_img\n",
    "        \n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "        inverted = cv2.bitwise_not(letter_square)\n",
    "        \n",
    "        letter = Letter(x,y,w,h,letter_square)\n",
    "        letters.append(letter)\n",
    "\n",
    "    letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "    aaa = Image.fromarray(output.astype('uint8'))\n",
    "    display(aaa)\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_extract2(image_file):\n",
    "    img = cv2.imread(image_file)\n",
    "    output = img.copy()\n",
    "    cv2.imshow('MyPhoto', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.blur(gray, (2, 2))\n",
    "#     cv2.imshow('blurred', blurred)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    #set a thresh\n",
    "    # thresh = 110\n",
    "    # ret, thresh_img = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)\n",
    "    # cv2.imshow('thresh_img', thresh_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    thresh_img = cv2.adaptiveThreshold(blurred, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,5,8)\n",
    "#     cv2.imshow('thresh_img', thresh_img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    #thresh_img = cv2.bitwise_not(thresh_img)\n",
    "\n",
    "    opening = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))\n",
    "#     cv2.imshow('opening', opening)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    closed = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8))\n",
    "#     cv2.imshow('closed', closed)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    img_erode = cv2.erode(closed, np.ones((3, 3), np.uint8), iterations=3)\n",
    "    #img_erode = cv2.dilate(img_erode, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "#     cv2.imshow('img_erode', img_erode)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "#     cv2.imshow('MyPhoto', img_contours )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    # Filter contours\n",
    "    mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 100 and cv2.contourArea(contour) < 10000:\n",
    "            cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "        else:\n",
    "            pass\n",
    "    #             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    #             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "    #             print(w*h, cv2.contourArea(contour))\n",
    "    #             cv2.imshow(str(idx), dummy )\n",
    "    #             cv2.waitKey(0)\n",
    "    #             cv2.destroyAllWindows()\n",
    "\n",
    "    #     # apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img,img, mask=mask)   \n",
    "#     cv2.imshow('result', mask )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "    cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "#     cv2.imshow('img_contours', img_contours )\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    letters = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        if hierarchy[0][idx][3] != -1:\n",
    "            continue\n",
    "    #         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "    #         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "    #         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "    #         cv2.imshow('MyPhoto', mask_contour)\n",
    "    #         cv2.waitKey(0)\n",
    "    #         cv2.destroyAllWindows()\n",
    "\n",
    "    #         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "    #         ii = cv2.imread('mask.png')\n",
    "    #         cv2.imshow('MyPhoto', ii )\n",
    "    #         cv2.waitKey(0)\n",
    "    #         cv2.destroyAllWindows()\n",
    "        crop_img = img_erode[y:y+h, x:x+w]\n",
    "        #crop_img = cv2.bitwise_not(crop_img)\n",
    "        #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "        size_max = max(w, h)\n",
    "        letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "        if w > h:\n",
    "            y_pos = size_max//2 - h//2\n",
    "            letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "        elif w < h:\n",
    "            x_pos = size_max//2 - w//2\n",
    "            letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "        else:\n",
    "            letter_square = crop_img\n",
    "\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "        inverted = cv2.bitwise_not(letter_square)\n",
    "\n",
    "        #aaa = transforms.ToPILImage()\n",
    "        #display(aaa(letter_square))\n",
    "\n",
    "        letter = Letter(x,y,w,h,letter_square)\n",
    "        letters.append(letter)\n",
    "\n",
    "    letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "    aaa = Image.fromarray(output.astype('uint8'))\n",
    "    display(aaa)\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2025e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_size(lst):\n",
    "    if len(lst) <= 0:\n",
    "        return (0, 0)\n",
    "    avg_w = 0\n",
    "    avg_h = 0\n",
    "    for letter in lst:\n",
    "        avg_w += letter.width\n",
    "        avg_h += letter.height\n",
    "    avg_w /= len(lst)\n",
    "    avg_h /= len(lst)\n",
    "    \n",
    "    return (avg_w, avg_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_str(model, image_file, tp=1):\n",
    "    if tp == 1:\n",
    "        letters = letters_extract(image_file)   \n",
    "    elif tp==2:\n",
    "        letters = letters_extract2(image_file)  \n",
    "    else:\n",
    "        return None\n",
    "    print('SHAPE: ', np.array(letters,dtype=object).shape)\n",
    "    s_out = \"\"\n",
    "    if len(letters) == 0:\n",
    "        return \"Found nothing\"\n",
    "    (avg_w, avg_h) = average_size(letters)\n",
    "    print((avg_w, avg_h))\n",
    "    \n",
    "    # True sorting by Y axis\n",
    "    line = 0\n",
    "    for i in range (1, len(letters)):\n",
    "        if letters[i].top > letters[i-1].bottom:\n",
    "            line += 1\n",
    "        letters[i].line = line\n",
    "    letters.sort(key=lambda ll: (ll.line, ll.x), reverse=False)  \n",
    "    \n",
    "    prev_loc = (letters[0].x, letters[0].y)\n",
    "    prev_size = (letters[0].width, letters[0].height)\n",
    "    prev_line = letters[0].line\n",
    "    for i in range(len(letters)):\n",
    "        img = Image.fromarray(letters[i].image.astype('uint8'))\n",
    "        convert_tensor = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.ToTensor()\n",
    "\n",
    "        ])        \n",
    "        x_image = convert_tensor(img)\n",
    "        aaa = transforms.ToPILImage()\n",
    "        display(aaa(x_image))\n",
    "        x_image = x_image.unsqueeze(0).float()\n",
    "        x_image = x_image.to(device)\n",
    "        pred = model(x_image) \n",
    "        am = map_pred(pred.argmax().item())\n",
    "        #print(letters[i].image.shape, map_pred(pred.argmax().item()), am)\n",
    "        #dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
    "        #print(am)\n",
    "        x = letters[i].x\n",
    "        y = letters[i].y\n",
    "        size = (letters[i].width, letters[i].height)\n",
    "        if (letters[i].line >  prev_line):\n",
    "            s_out += \"\\n\"\n",
    "            prev_line = letters[i].line\n",
    "        prev_loc, prev_size = (x,y), size\n",
    "        s_out += am + ' '\n",
    "        print(letters[i].image.shape, map_pred(pred.argmax().item()), am)\n",
    "        \n",
    "    return s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38953a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MathNet()\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print('EVALUATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf68e22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = img_to_str(model, 'real1.jpg')\n",
    "print('RESULT:')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cc3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a8dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread('real4.jpg')\n",
    "output = img.copy()\n",
    "cv2.imshow('MyPhoto', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.blur(gray, (3, 3))\n",
    "cv2.imshow('blurred', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#set a thresh\n",
    "thresh = 110\n",
    "ret, thresh_img = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# cv2.imshow('thresh_img', thresh_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "thresh_img = cv2.adaptiveThreshold(blurred, 255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,5,8)\n",
    "cv2.imshow('thresh_img', thresh_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#thresh_img = cv2.bitwise_not(thresh_img)\n",
    "\n",
    "# opening = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# closed = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8))\n",
    "# cv2.imshow('closed', closed)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "img_erode = cv2.erode(thresh_img, np.ones((3, 3), np.uint8), iterations=1)\n",
    "#img_erode = cv2.dilate(img_erode, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "cv2.imshow('img_erode', img_erode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Get contours\n",
    "contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)       \n",
    "img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "cv2.imshow('MyPhoto', img_contours )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Filter contours\n",
    "mask = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "for idx, contour in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    if cv2.contourArea(contour) > 10 and cv2.contourArea(contour) < 10000:\n",
    "        cv2.drawContours(mask, [contour], 0, (255), -1)\n",
    "    else:\n",
    "        pass\n",
    "#             dummy = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "#             cv2.drawContours(dummy, contour, -1, (255,255,255), 1)\n",
    "#             print(w*h, cv2.contourArea(contour))\n",
    "#             cv2.imshow(str(idx), dummy )\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "\n",
    "#     # apply the mask to the original image\n",
    "result = cv2.bitwise_and(img,img, mask=mask)   \n",
    "cv2.imshow('result', mask )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "img_contours = np.uint8(np.zeros((img.shape[0],img.shape[1])))\n",
    "cv2.drawContours(img_contours, contours, -1, (255,255,255), 1)\n",
    "cv2.imshow('img_contours', img_contours )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "letters = []\n",
    "for idx, contour in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    #print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "    if hierarchy[0][idx][3] != -1:\n",
    "        continue\n",
    "#         mask_contour = img_contours[y:y+h, x:x+w]\n",
    "#         mask_contour[y_pos:y_pos + h, 0:w] = crop_img\n",
    "#         cv2.drawContours(mask_contour, contour, -1, (255,255,255), 1)\n",
    "#         cv2.imshow('MyPhoto', mask_contour)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#         cv2.imwrite('mask.png', img * max(img - 100, 0) * 255)\n",
    "#         ii = cv2.imread('mask.png')\n",
    "#         cv2.imshow('MyPhoto', ii )\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    crop_img = img_erode[y:y+h, x:x+w]\n",
    "    #crop_img = cv2.bitwise_not(crop_img)\n",
    "    #crop_img = thresh_img[y:y+h, x:x+w]\n",
    "    size_max = max(w, h)\n",
    "    letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "    if w > h:\n",
    "        y_pos = size_max//2 - h//2\n",
    "        letter_square[y_pos:y_pos + h, 0:w] = crop_img\n",
    "    elif w < h:\n",
    "        x_pos = size_max//2 - w//2\n",
    "        letter_square[0:h, x_pos:x_pos + w] = crop_img\n",
    "    else:\n",
    "        letter_square = crop_img\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    rect = cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255,0), 2)      \n",
    "    inverted = cv2.bitwise_not(letter_square)\n",
    "    \n",
    "    aaa = transforms.ToPILImage()\n",
    "    display(aaa(letter_square))\n",
    "    \n",
    "    letter = Letter(x,y,w,h,letter_square)\n",
    "    letters.append(letter)\n",
    "\n",
    "letters.sort(key=lambda ll: (ll.y, ll.x), reverse=False)\n",
    "aaa = Image.fromarray(output.astype('uint8'))\n",
    "display(aaa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb448a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4c1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e0425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af59fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a15b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28961b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a9881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603e35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
